# Amazon Bedrock 実践ハンズオン

## 1. はじめに

### 1.1 目的
このハンズオンは、Amazon Bedrockを業務で効果的に活用するための基本的なユースケースを実践的に学ぶことを目的としています。
日常業務で直面する具体的なタスクに対して、Bedrockをどのように活用できるかを体験的に理解することができます。

### 1.2 対象者
- Bedrockをまだ業務で日常的に活用できていない方
- 基本的なAIの概念は理解しているが、実践的な活用方法を学びたい方
- 具体的なユースケースでの活用方法を知りたい方

### 1.3 利用可能なモデルとコスト

#### モデル別コスト比較
| モデル名 | 入力コスト ($/1M トークン) | 出力コスト ($/1M トークン) |
|----------|--------------------------|--------------------------|
| Amazon Nova Micro | $0.035 | $0.14 |
| Amazon Nova Lite | $0.06 | $0.24 |
| Amazon Nova Pro | $0.80 | $3.20 |
| Claude 3.5 Haiku | $0.80 | $4.00 |
| Claude 3.5 Sonnet | $3.00 | $15.00 |
| Claude 3.5 Sonnet v2 | $3.00 | $15.00 |

#### モデル特性
- **Amazon Nova シリーズ**
  - Nova Micro/Lite：低コストで効率的なドキュメント生成が可能
  - 特に議事録作成や文書要約に最適
  - コストパフォーマンスが高く、日常的な文書作成タスクに推奨

- **Claude 3.5 シリーズ**
  - プログラミングコード生成において高い精度
  - コードの解説や最適化も得意
  - VBAやSQLなどの開発タスクに最適

## 2. 生成AIの基本的な理解

### 2.1 生成AIとは
生成AIは本質的に「情報変換器」として機能します。入力された情報（情報A）を、プロンプト（変換指示）を介して新しい形式や構造の情報（情報B）に変換します。

### 2.2 情報変換の3要素

#### 1. 入力情報（変換元）
- **必要十分な情報の重要性**
  - 出力の品質は入力情報の質と量に直接依存
  - 不足している情報があると、AIは推測や一般化で補完しようとする
  - 過剰な情報は処理時間とコストの無駄になるのでMECE原則を意識

**良い入力情報の例**：
```
【会議記録の変換例】
変換前の情報：
- 日時、場所、参加者の完全な情報
- 議題の明確な列挙
- 各議題での決定事項
- 次回アクションの担当者と期限

【コード生成の例】
変換前の情報：
- 詳細な機能要件
- 入出力データの形式
- エラーケースの定義
- パフォーマンス要件
```

#### 2. プロンプト（変換指示）
- **明確な指示の重要性**
  - 変換の目的を具体的に指定
  - 出力形式を明示的に定義
  - 制約条件や要件を明確に記述

  **何よりも成果物を描けないとプロンプトを作成できることはできない**

**効果的なプロンプトの構造**：
```
1. 目的の明示
   「〇〇を△△の形式に変換してください」

2. 出力形式の指定
   「以下の形式で出力してください：
    - 項目1：[形式]
    - 項目2：[形式]」

3. 制約条件
   「ただし、以下の条件を満たすこと：
    - 条件1
    - 条件2」
```

#### 3. 出力情報（変換結果）
- **品質確認のポイント**
  - 入力情報の重要な要素がすべて反映されているか
  - 指定した形式や構造が守られているか
  - 制約条件が遵守されているか

  **今後AIでできる事、できるスピードがどんどん進化するため、成果物の精度判断力が非常に大事になる**

### 2.3 効果的な変換のための原則

1. **入力情報の準備**
   - 必要な情報を漏れなく収集
   - 情報の正確性を確認
   - 余分な情報を除去

2. **プロンプトの設計**
   - 変換の目的を明確に
   - 具体的な指示を提供
   - 期待する出力形式を明示

3. **結果の検証**
   - 出力内容の完全性確認
   - 形式要件との整合性確認
   - 必要に応じた再変換

## 3. 実践ユースケース

### 以下環境を使います
https://d2rfq9mexxexuq.cloudfront.net/

### 3.1 ドキュメント処理系タスク
推奨モデル：Amazon Nova Micro/Lite（コスト効率の高い文書生成）

#### 3.1.1 議事録作成
**手順**
1. 会議メモやZoom文字起こしの準備
2. Nova Microでの議事録生成プロンプトを選択し、情報入力
3. 重要ポイントの抽出と構造化ができているか判断

**サンプルプロンプト**
```
サンプルプロンプト「議事録作成_マークダウンあり」

【背景情報】
{{どんなMTGだったかを簡単に記載}}

【文字起こし内容】
{{文字起こし内容}}
...
```

#### 3.1.2 社内メール情報集約
**手順**
1. 社内メールのテキストをコピー
2. Nova Liteでのサンプルプロンプトと情報を入力
3. 重要情報の抽出とカテゴリ分類が適切か判断

**サンプルプロンプト**
```
以下のメール情報から重要な情報を抽出し、
以下の形式でまとめてください：
- 内容：[内容をマークダウン形式で]
- タスクリスト：[タスクリストを表形式で]

【メール内容】
{{内容}}
```

### 3.2 コーディング系タスク
推奨モデル：Claude 3.5シリーズ（高精度なコード生成）

#### 3.2.1 VBAコード生成
**手順**
1. 要件の明確化
2. Claude 3.5 Haikuでのコード生成
3. コードレビューと最適化

**サンプルプロンプト**
```
以下の機能を持つVBAコードを生成してください：
1. 現在のファイルパスを取得
2. 同じ階層にあるファイルのパスをリストアップ
3. csvにパスのリストを上から書き込んでファイル名「llm_samplecode」新規保存
4．コメントアウトも含めてください
5. エラー処理も含めてください
```

#### 3.2.2 SQLコード生成
**手順**
1. テーブル定義の確認
2. Claude 3.5 Sonnetでのクエリ生成
3. パフォーマンス最適化

**サンプルプロンプト**
```
以下のテーブルに対するSQLクエリを作成してください：
1. 要件：月次売上レポート
2. 必要な集計：
   - 商品カテゴリ別売上
   - 地域別売上推移
   - 前年同月比
3. パフォーマンスを考慮した実装
```

## 4. 会話履歴について

### 4.1 会話履歴の仕組み

生成AIの会話履歴は一般的に考えられているような「記憶」ではありません。
以下が実際の処理の仕組みです：

1. **会話履歴の処理方法**
   - 各リクエスト時に過去の全会話履歴を再読込
   - 会話履歴全体を含めた新しいコンテキストで推論を実行
   - 「記憶」ではなく「その都度の読み込みと処理」

2. **会話履歴の増加による影響**
   - 処理すべき情報量の増加
   - トークン数の増加によるコストの上昇
   - 文脈の複雑化による推論精度の低下

### 4.2 実務上の考慮点

1. **コストへの影響**
   - 会話履歴の長さに比例してトークン消費が増加
   - 特に長文や技術文書では顕著なコスト増加
   - 不要な履歴の蓄積によるコスト無駄を防ぐ必要性

2. **推論品質への影響**
   - 履歴が長くなるほど重要な情報の埋没リスク
   - 文脈の混乱による精度低下の可能性
   - 適切なタイミングでの会話リセットの重要性

## 5. ワークフローについて

通常のチャットでも基本的な処理は可能ですが、より複雑な業務プロセスではワークフローによる段階的な処理が効果的です。

### 5.1 段階的処理の重要性

複雑なタスクを複数のステップに分解することで、以下が実現できます：

1. **処理の最適化**
   - 各ステップで最適なtoolを選択可能
      - **tool**とはfunction callingとも呼ばれ、AIに備わってない外部機能を呼び出す処理のこと
   - 処理結果に応じた分岐処理
   - エラー発生時の代替ルート設定（エラー処理）

2. **外部連携の制御**
   - SaaS/DB接続の使い分け
   - RAGシステムの効率的な活用
   - 複数APIの連携タイミング調整

3. **品質の段階的向上**
   - ステップごとの結果検証
   - 必要に応じた処理の再実行
   - 最終成果物の品質担保

### 5.2 ワークフロー活用例

```
例：技術文書生成プロセス

1. 前処理ステップ
   - 過去の類似文書の検索・参照
   - 最新技術情報のWEB収集
   - 参照すべき規格書の特定
   → 各情報源の特性に応じたtools選択で情報収集を効率化

2. 文書生成ステップ
   - 基本構成のテキスト生成
   - コードサンプルの作成
   - 図表の自動生成
   → 内容に応じて最適なモデルを使い分け

3. 検証ステップ
   - コードの動作確認
   - 参照リンクの有効性確認
   - 用語の一貫性チェック
   → 各検証項目に特化したツールで精度向上

4. 最終調整ステップ
   - レイアウト最適化
   - 最終形式(PDFなど) へPythonやAPIを活用して変換
   → 出力形式に応じた専用toolの活用
```

このように、各ステップで最適なツールを選択し、その結果を検証しながら進めることで、高品質な成果物を効率的に作成できます。複雑な処理や判断が必要な場合でも、ステップごとの制御が可能になります。

さらに、4章で説明した会話履歴もワークフローを通じてコントロールできるため、より柔軟な運用が可能です。各ステップで必要な文脈のみを保持することで、精度とコストの最適化も実現できます。

## Appendix

### A.1 用語集

1. **LLM (Large Language Model)**
   - 大規模言語モデル
   - 膨大なテキストデータで学習された AI モデル
   - テキスト生成、理解、翻訳などの言語タスクを実行可能

2. **プロンプトエンジニアリング**
   - AIモデルに適切な指示を与えるための技術
   - 出力の品質を向上させるための手法
   - システマティックな指示の設計方法

3. **RAG (Retrieval Augmented Generation)**
   - 外部文書やデータを検索・参照しながら情報生成を行う手法
   - 文書の検索（Retrieval）と生成（Generation）を組み合わせる
   - モデルの知識を外部データで補完する手法

4. **Tool/Function Calling**
   - AIモデルに組み込まれていない外部機能を呼び出す処理
   - データベースアクセス、API呼び出し、ファイル操作など
   - 複雑な処理を実現するための拡張機能

5. **トークン (Token)**
   - AIモデルが処理する最小単位の文字列
   - 日本語は1文字が複数のトークンに分割されることも
   - コスト計算の基準となる単位

6. **ファインチューニング**
   - 事前学習済みモデルを特定のタスク用に調整すること
   - 特定ドメインや用途に特化させる手法
   - データセットを用いた追加学習プロセス

7. **ベクトルデータベース**
   - テキストや画像をベクトル形式で格納するDB
   - 類似度検索に特化したデータベース
   - RAGシステムでよく使用される

8. **embbeding(エンベディング)**
   - テキストや画像を数値ベクトルに変換
   - 意味的な類似性を計算可能な形式
   - 検索や分類に活用される技術
